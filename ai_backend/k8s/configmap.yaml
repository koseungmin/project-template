apiVersion: v1
kind: ConfigMap
metadata:
  name: ai-backend-config
  namespace: default
  labels:
    app: ai-backend
    component: config
data:
  # Application Configuration
  APP_VERSION: "1.0.0"
  APP_LOCALE: "ko"
  APP_LOG_LEVEL: "info"
  APP_DEBUG: "false"
  APP_ROOT_PATH: ""
  
  # Server Configuration
  SERVER_HOST: "0.0.0.0"
  SERVER_PORT: "8000"
  SERVER_DEBUG: "false"
  SERVER_RELOAD: "false"
  SERVER_LOG_LEVEL: "info"
  
  # CORS Configuration
  CORS_ORIGINS: "http://localhost:3000,https://yourdomain.com"
  
  # Logging Configuration
  LOG_TO_FILE: "false"
  LOG_DIR: "/var/log/ai-backend"
  LOG_FILE: "app.log"
  LOG_ROTATION: "daily"
  LOG_RETENTION_DAYS: "30"
  
  # Database Configuration
  DATABASE_HOST: "postgres-service"
  DATABASE_PORT: "5432"
  DATABASE_NAME: "chat_db"
  DATABASE_USERNAME: "postgres"
  
  # LLM Provider Configuration
  LLM_PROVIDER: "azure_openai"  # openai or azure_openai
  
  # OpenAI Configuration
  OPENAI_MODEL: "gpt-3.5-turbo"
  OPENAI_MAX_TOKENS: "1000"
  OPENAI_TEMPERATURE: "0.7"
  
  # Azure OpenAI Configuration
  AZURE_OPENAI_ENDPOINT: "https://your-resource.openai.azure.com/"
  AZURE_OPENAI_API_VERSION: "2024-12-01-preview"
  AZURE_OPENAI_DEPLOYMENT_NAME: "your-deployment-name"
  AZURE_OPENAI_MAX_TOKENS: "1000"
  AZURE_OPENAI_TEMPERATURE: "0.7"
  
  # Cache Configuration
  CACHE_ENABLED: "false"
  CACHE_TTL_CHAT_MESSAGES: "1800"
  CACHE_TTL_USER_CHATS: "600"
  
  # Redis Configuration
  REDIS_HOST: "redis-service"
  REDIS_PORT: "6379"
  REDIS_DB: "0"
  
  # File Upload Configuration
  UPLOAD_BASE_PATH: "/app/uploads"
  UPLOAD_MAX_SIZE: "52428800"  # 50MB in bytes
  UPLOAD_ALLOWED_TYPES: "pdf,txt,doc,docx,jpg,jpeg,png,gif,xls,xlsx"
  
  # Logging Configuration
  LOG_INCLUDE_EXC_INFO: "true"