# _*_ coding: utf-8 _*_
"""
ê³µí†µ ë¬¸ì„œ ì„œë¹„ìŠ¤
Backendì™€ Prefect í”„ë¡œì íŠ¸ì—ì„œ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë¬¸ì„œ ê´€ë ¨ ì„œë¹„ìŠ¤ë“¤
"""

import hashlib
import logging
import mimetypes
import os
import uuid
from datetime import datetime
from pathlib import Path
from typing import BinaryIO, Dict, List, Optional, Union

from sqlalchemy.orm import Session

from .crud import DocumentChunkCRUD, DocumentCRUD, ProcessingJobCRUD
from .models import Document, DocumentChunk, ProcessingJob

logger = logging.getLogger(__name__)


class DocumentService:
    """ê³µí†µ ë¬¸ì„œ ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self, db: Session, upload_base_path: str = None):
        self.db = db
        self.upload_base_path = Path(upload_base_path) if upload_base_path else Path("uploads")
        self.upload_base_path.mkdir(parents=True, exist_ok=True)
        self.document_crud = DocumentCRUD(db)
        self.chunk_crud = DocumentChunkCRUD(db)
        self.job_crud = ProcessingJobCRUD(db)
    
    def _get_file_extension(self, filename: str) -> str:
        """íŒŒì¼ í™•ì¥ì ì¶”ì¶œ (. ì œê±°)"""
        return Path(filename).suffix.lower().lstrip('.')
    
    def _get_mime_type(self, filename: str) -> str:
        """MIME íƒ€ì… ì¶”ì¶œ"""
        mime_type, _ = mimetypes.guess_type(filename)
        return mime_type or 'application/octet-stream'
    
    def _calculate_file_hash(self, file_content: bytes) -> str:
        """íŒŒì¼ í•´ì‹œê°’ ê³„ì‚° (MD5, 4096 ë°”ì´íŠ¸ ì²­í¬ ë‹¨ìœ„)"""
        hash_md5 = hashlib.md5()
        # 4096 ë°”ì´íŠ¸ì”© ì²­í¬ ë‹¨ìœ„ë¡œ í•´ì‹œ ê³„ì‚°
        for i in range(0, len(file_content), 4096):
            chunk = file_content[i:i+4096]
            hash_md5.update(chunk)
        return hash_md5.hexdigest()
    
    def _generate_file_key(self, user_id: str, filename: str = None) -> str:
        """íŒŒì¼ í‚¤ ìƒì„± (ì €ì¥ ê²½ë¡œ)"""
        # í´ë” êµ¬ì¡°: uploads/user_id/filename
        return f"{user_id}/{filename}"
    
    def _get_upload_path(self, file_key: str) -> Path:
        """ì‹¤ì œ ì—…ë¡œë“œ ê²½ë¡œ ìƒì„±"""
        return self.upload_base_path / file_key
    
    def create_document_from_file(
        self,
        file_content: bytes,
        filename: str,
        user_id: str,
        is_public: bool = False,
        permissions: List[str] = None,
        document_type: str = 'common',
        **additional_metadata
    ) -> Dict:
        """íŒŒì¼ ë‚´ìš©ìœ¼ë¡œë¶€í„° ë¬¸ì„œ ìƒì„±"""
        try:
            # íŒŒì¼ ì •ë³´ ì¶”ì¶œ
            file_extension = self._get_file_extension(filename)
            file_type = self._get_mime_type(filename)
            file_size = len(file_content)
            file_hash = self._calculate_file_hash(file_content)
            
            # ì¤‘ë³µ íŒŒì¼ ì²´í¬
            existing_doc = self.document_crud.find_document_by_hash(file_hash)
            if existing_doc and existing_doc.status == 'completed':
                logger.info(f"ğŸ“‹ ì™„ë£Œëœ ê¸°ì¡´ ë¬¸ì„œ ë°œê²¬: {existing_doc.document_id}")
                return self._document_to_dict(existing_doc, is_duplicate=True)
            
            # ê³ ìœ í•œ ë¬¸ì„œ ID ìƒì„±
            if existing_doc and existing_doc.status in ['processing', 'failed']:
                document_id = existing_doc.document_id
                logger.info(f"ğŸ”„ ê¸°ì¡´ ë¬¸ì„œ ì¬ì²˜ë¦¬: {document_id}")
            else:
                document_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file_hash[:8]}"
            
            # íŒŒì¼ ì €ì¥
            file_key = self._generate_file_key(user_id, filename)
            upload_path = self._get_upload_path(file_key)
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            upload_path.parent.mkdir(parents=True, exist_ok=True)
            
            # íŒŒì¼ ì €ì¥
            with open(upload_path, "wb") as f:
                f.write(file_content)
            
            # DBì— ë©”íƒ€ë°ì´í„° ì €ì¥
            if existing_doc and existing_doc.status in ['failed', 'processing']:
                # ê¸°ì¡´ ë¬¸ì„œ ì—…ë°ì´íŠ¸
                self.document_crud.update_document(
                    document_id,
                    document_name=filename,
                    original_filename=filename,
                    file_key=file_key,
                    file_size=file_size,
                    file_type=file_type,
                    file_extension=file_extension,
                    user_id=user_id,
                    upload_path=str(upload_path),
                    is_public=is_public,
                    status='processing',
                    permissions=permissions,
                    document_type=document_type,
                    **additional_metadata
                )
                document = self.document_crud.get_document(document_id)
            else:
                # ìƒˆ ë¬¸ì„œ ìƒì„±
                document = self.document_crud.create_document(
                    document_id=document_id,
                    document_name=filename,
                    original_filename=filename,
                    file_key=file_key,
                    file_size=file_size,
                    file_type=file_type,
                    file_extension=file_extension,
                    user_id=user_id,
                    upload_path=str(upload_path),
                    is_public=is_public,
                    file_hash=file_hash,
                    status='processing',
                    permissions=permissions,
                    document_type=document_type,
                    **additional_metadata
                )
            
            return self._document_to_dict(document)
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def create_document_from_path(
        self,
        file_path: str,
        user_id: str,
        is_public: bool = False,
        permissions: List[str] = None,
        document_type: str = 'common',
        **additional_metadata
    ) -> Dict:
        """íŒŒì¼ ê²½ë¡œë¡œë¶€í„° ë¬¸ì„œ ìƒì„±"""
        file_path = Path(file_path)
        if not file_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        with open(file_path, "rb") as f:
            file_content = f.read()
        
        return self.create_document_from_file(
            file_content=file_content,
            filename=file_path.name,
            user_id=user_id,
            is_public=is_public,
            permissions=permissions,
            document_type=document_type,
            **additional_metadata
        )
    
    def get_document(self, document_id: str, user_id: str = None) -> Optional[Dict]:
        """ë¬¸ì„œ ì •ë³´ ì¡°íšŒ"""
        try:
            document = self.document_crud.get_document(document_id)
            
            if not document or document.is_deleted:
                return None
            
            # ì‚¬ìš©ì ê¶Œí•œ ì²´í¬ (user_idê°€ ì œê³µëœ ê²½ìš°)
            if user_id and document.user_id != user_id and not document.is_public:
                return None
            
            return self._document_to_dict(document)
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def get_user_documents(self, user_id: str) -> List[Dict]:
        """ì‚¬ìš©ìì˜ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
        try:
            documents = self.document_crud.get_user_documents(user_id)
            return [self._document_to_dict(doc) for doc in documents]
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def search_documents(self, user_id: str, search_term: str) -> List[Dict]:
        """ë¬¸ì„œ ê²€ìƒ‰"""
        try:
            documents = self.document_crud.search_documents(user_id, search_term)
            return [self._document_to_dict(doc) for doc in documents]
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def download_document(self, document_id: str, user_id: str = None) -> tuple[bytes, str, str]:
        """ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ"""
        try:
            document = self.document_crud.get_document(document_id)
            
            if not document or document.is_deleted:
                raise FileNotFoundError("ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‚¬ìš©ì ê¶Œí•œ ì²´í¬ (user_idê°€ ì œê³µëœ ê²½ìš°)
            if user_id and document.user_id != user_id and not document.is_public:
                raise PermissionError("ë¬¸ì„œì— ì ‘ê·¼í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # íŒŒì¼ ì½ê¸°
            upload_path = Path(document.upload_path)
            if not upload_path.exists():
                raise FileNotFoundError("íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
            with open(upload_path, "rb") as f:
                file_content = f.read()
            
            return file_content, document.original_filename, document.file_type
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def delete_document(self, document_id: str, user_id: str = None) -> bool:
        """ë¬¸ì„œ ì‚­ì œ"""
        try:
            document = self.document_crud.get_document(document_id)
            
            if not document:
                return False
            
            # ì‚¬ìš©ì ê¶Œí•œ ì²´í¬ (user_idê°€ ì œê³µëœ ê²½ìš°)
            if user_id and document.user_id != user_id:
                raise PermissionError("ë¬¸ì„œë¥¼ ì‚­ì œí•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # DBì—ì„œ ì†Œí”„íŠ¸ ì‚­ì œ
            success = self.document_crud.delete_document(document_id)
            
            # ê´€ë ¨ ì²­í¬ë“¤ë„ ì‚­ì œ
            if success:
                self.chunk_crud.delete_document_chunks(document_id)
                
                # ì‹¤ì œ íŒŒì¼ë„ ì‚­ì œ (ì„ íƒì‚¬í•­)
                upload_path = Path(document.upload_path)
                if upload_path.exists():
                    upload_path.unlink()
            
            return success
                
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def update_document_processing_status(
        self,
        document_id: str,
        status: str,
        user_id: str = None,
        **processing_info
    ) -> bool:
        """ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ë° ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            # ê¶Œí•œ í™•ì¸ (user_idê°€ ì œê³µëœ ê²½ìš°)
            if user_id:
                document = self.document_crud.get_document(document_id)
                if not document or document.user_id != user_id:
                    raise PermissionError("ë¬¸ì„œë¥¼ ìˆ˜ì •í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.")
            
            # ìƒíƒœ ì—…ë°ì´íŠ¸
            self.document_crud.update_document_status(document_id, status)
            
            # ì¶”ê°€ ì²˜ë¦¬ ì •ë³´ ì—…ë°ì´íŠ¸
            if processing_info:
                self.document_crud.update_processing_info(document_id, **processing_info)
            
            return True
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def get_document_processing_stats(self, user_id: str) -> Dict:
        """ì‚¬ìš©ì ë¬¸ì„œ ì²˜ë¦¬ í†µê³„ ì¡°íšŒ"""
        try:
            documents = self.document_crud.get_user_documents(user_id)
            
            stats = {
                'total_documents': len(documents),
                'processing': 0,
                'completed': 0,
                'failed': 0,
                'total_pages': 0,
                'processed_pages': 0,
                'total_vectors': 0
            }
            
            for doc in documents:
                if doc.status == 'processing':
                    stats['processing'] += 1
                elif doc.status == 'completed':
                    stats['completed'] += 1
                elif doc.status == 'failed':
                    stats['failed'] += 1
                
                if doc.total_pages:
                    stats['total_pages'] += doc.total_pages
                if doc.processed_pages:
                    stats['processed_pages'] += doc.processed_pages
                if doc.vector_count:
                    stats['total_vectors'] += doc.vector_count
            
            # ì²˜ë¦¬ ì§„í–‰ë¥  ê³„ì‚°
            if stats['total_pages'] > 0:
                stats['processing_progress'] = round((stats['processed_pages'] / stats['total_pages']) * 100, 2)
            else:
                stats['processing_progress'] = 0.0
            
            return stats
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _document_to_dict(self, document: Document, is_duplicate: bool = False) -> Dict:
        """Document ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "document_id": document.document_id,
            "document_name": document.document_name,
            "original_filename": document.original_filename,
            "file_size": document.file_size,
            "file_type": document.file_type,
            "file_extension": document.file_extension,
            "file_hash": document.file_hash,
            "upload_path": document.upload_path,
            "is_public": document.is_public,
            "status": document.status,
            "total_pages": document.total_pages,
            "processed_pages": document.processed_pages,
            "vector_count": document.vector_count,
            "milvus_collection_name": document.milvus_collection_name,
            "language": document.language,
            "author": document.author,
            "subject": document.subject,
            "metadata_json": document.metadata_json,
            "processing_config": document.processing_config,
            "permissions": document.permissions or [],
            "document_type": document.document_type or 'common',
            "create_dt": document.create_dt.isoformat(),
            "updated_at": document.updated_at.isoformat() if document.updated_at else None,
            "processed_at": document.processed_at.isoformat() if document.processed_at else None,
            "is_duplicate": is_duplicate
        }


class DocumentChunkService:
    """ë¬¸ì„œ ì²­í¬ ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self, db: Session):
        self.db = db
        self.chunk_crud = DocumentChunkCRUD(db)
    
    def create_chunk(
        self,
        doc_id: str,
        page_number: int,
        chunk_type: str,
        content: str = None,
        image_description: str = None,
        image_path: str = None,
        **additional_data
    ) -> Dict:
        """ë¬¸ì„œ ì²­í¬ ìƒì„±"""
        try:
            chunk_id = f"{doc_id}_page_{page_number}_{chunk_type}_{uuid.uuid4().hex[:8]}"
            
            # í…ìŠ¤íŠ¸ í†µê³„ ê³„ì‚°
            text_content = content or ""
            char_count = len(text_content) if text_content else 0
            word_count = len(text_content.split()) if text_content else 0
            
            chunk = self.chunk_crud.create_chunk(
                chunk_id=chunk_id,
                doc_id=doc_id,
                page_number=page_number,
                chunk_type=chunk_type,
                content=content,
                image_description=image_description,
                image_path=image_path,
                char_count=char_count,
                word_count=word_count,
                **additional_data
            )
            
            return self._chunk_to_dict(chunk)
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²­í¬ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def get_document_chunks(self, doc_id: str) -> List[Dict]:
        """ë¬¸ì„œì˜ ëª¨ë“  ì²­í¬ ì¡°íšŒ"""
        try:
            chunks = self.chunk_crud.get_document_chunks(doc_id)
            return [self._chunk_to_dict(chunk) for chunk in chunks]
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì²­í¬ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def update_chunk(self, chunk_id: str, **kwargs) -> bool:
        """ì²­í¬ ì •ë³´ ì—…ë°ì´íŠ¸"""
        try:
            return self.chunk_crud.update_chunk(chunk_id, **kwargs)
            
        except Exception as e:
            logger.error(f"ì²­í¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def delete_chunk(self, chunk_id: str) -> bool:
        """ì²­í¬ ì‚­ì œ"""
        try:
            return self.chunk_crud.delete_chunk(chunk_id)
            
        except Exception as e:
            logger.error(f"ì²­í¬ ì‚­ì œ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _chunk_to_dict(self, chunk: DocumentChunk) -> Dict:
        """DocumentChunk ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "id": str(chunk.id),
            "chunk_id": chunk.chunk_id,
            "doc_id": chunk.doc_id,
            "page_number": chunk.page_number,
            "chunk_type": chunk.chunk_type,
            "content": chunk.content,
            "image_description": chunk.image_description,
            "image_path": chunk.image_path,
            "milvus_id": chunk.milvus_id,
            "embedding_model": chunk.embedding_model,
            "vector_dimension": chunk.vector_dimension,
            "char_count": chunk.char_count,
            "word_count": chunk.word_count,
            "language": chunk.language,
            "metadata_json": chunk.metadata_json,
            "created_at": chunk.created_at.isoformat(),
            "updated_at": chunk.updated_at.isoformat()
        }


class ProcessingJobService:
    """ì²˜ë¦¬ ì‘ì—… ê´€ë¦¬ ì„œë¹„ìŠ¤"""
    
    def __init__(self, db: Session):
        self.db = db
        self.job_crud = ProcessingJobCRUD(db)
    
    def create_job(
        self,
        doc_id: str,
        job_type: str,
        flow_run_id: str = None,
        total_steps: int = 0
    ) -> Dict:
        """ì²˜ë¦¬ ì‘ì—… ìƒì„±"""
        try:
            job_id = f"job_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:8]}"
            
            job = self.job_crud.create_job(
                job_id=job_id,
                doc_id=doc_id,
                job_type=job_type,
                flow_run_id=flow_run_id,
                total_steps=total_steps
            )
            
            return self._job_to_dict(job)
            
        except Exception as e:
            logger.error(f"ì²˜ë¦¬ ì‘ì—… ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
    
    def update_job_status(self, job_id: str, status: str, **kwargs) -> bool:
        """ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸"""
        try:
            return self.job_crud.update_job_status(job_id, status, **kwargs)
            
        except Exception as e:
            logger.error(f"ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def get_document_jobs(self, doc_id: str) -> List[Dict]:
        """ë¬¸ì„œì˜ ëª¨ë“  ì‘ì—… ì¡°íšŒ"""
        try:
            jobs = self.job_crud.get_document_jobs(doc_id)
            return [self._job_to_dict(job) for job in jobs]
            
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ì‘ì—… ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            raise
    
    def _job_to_dict(self, job: ProcessingJob) -> Dict:
        """ProcessingJob ê°ì²´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "id": str(job.id),
            "job_id": job.job_id,
            "doc_id": job.doc_id,
            "job_type": job.job_type,
            "status": job.status,
            "flow_run_id": job.flow_run_id,
            "total_steps": job.total_steps,
            "completed_steps": job.completed_steps,
            "current_step": job.current_step,
            "result_data": job.result_data,
            "error_message": job.error_message,
            "started_at": job.started_at.isoformat(),
            "completed_at": job.completed_at.isoformat() if job.completed_at else None,
            "updated_at": job.updated_at.isoformat()
        }
