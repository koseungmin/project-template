#!/usr/bin/env python3
"""
Milvus ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (Prefect ì—†ì´)
"""

import sys
import os
from pathlib import Path
from typing import List, Dict, Any
import logging
import time

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent))

# Milvus
from pymilvus import Collection, connections, utility

# Azure OpenAI (ì„ë² ë”©ìš©)
import openai

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Milvus Lite ì„¤ì • (íŒŒì¼ ê¸°ë°˜)
MILVUS_URI = os.getenv("MILVUS_URI", "./milvus_lite.db")  # íŒŒì¼ ê¸°ë°˜ DB
MILVUS_COLLECTION_NAME = os.getenv("MILVUS_COLLECTION_NAME", "document_vectors")

# Azure OpenAI ì„¤ì •
AZURE_OPENAI_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_KEY = os.getenv("AZURE_OPENAI_KEY")
AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv("AZURE_OPENAI_EMBEDDING_API_VERSION", "2023-12-01-preview")
AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT")

def get_azure_openai_embedding(text: str) -> List[float]:
    """Azure OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # Azure OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        client = openai.AzureOpenAI(
            azure_endpoint=AZURE_OPENAI_ENDPOINT,
            api_key=AZURE_OPENAI_KEY,
            api_version=AZURE_OPENAI_EMBEDDING_API_VERSION
        )
        
        response = client.embeddings.create(
            model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        logger.error(f"âŒ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {str(e)}")
        raise

def _get_embedding_dim_from_schema(collection: Collection) -> int:
    """ì»¬ë ‰ì…˜ ìŠ¤í‚¤ë§ˆì—ì„œ ì„ë² ë”© ì°¨ì›ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        for field in collection.schema.fields:
            if field.name == "embedding":
                # PyMilvus ë²„ì „ì— ë”°ë¼ dim ì†ì„± ë˜ëŠ” params ì‚¬ìš©
                dim_value = getattr(field, "dim", None)
                if dim_value:
                    return int(dim_value)
                params = getattr(field, "params", None)
                if isinstance(params, dict) and "dim" in params:
                    return int(params["dim"])
    except Exception:
        pass
    # íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ê°’
    return 3072

def debug_and_prepare_collection() -> Collection:
    """ì»¬ë ‰ì…˜ ë¡œë“œ, ì¸ë±ìŠ¤/ìŠ¤í‚¤ë§ˆ ì ê²€ ë° ì¤€ë¹„ (Milvus Lite)."""
    connections.connect("default", uri=MILVUS_URI)
    collection = Collection(MILVUS_COLLECTION_NAME)

    # flush/load ë³´ì¥
    try:
        collection.flush()
    except Exception:
        pass

    collection.load()

    # ì¸ë±ìŠ¤/ìŠ¤í‚¤ë§ˆ ë¡œê¹…
    try:
        index_types = []
        for ix in collection.indexes:
            ix_type = getattr(ix, "index_type", None) or str(ix)
            index_types.append(ix_type)
        logger.info(f"ğŸ“‹ ì¸ë±ìŠ¤: {index_types}")
    except Exception:
        logger.info("ğŸ“‹ ì¸ë±ìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•¨")

    try:
        field_names = [f.name for f in collection.schema.fields]
        logger.info(f"ğŸ§¬ ìŠ¤í‚¤ë§ˆ í•„ë“œ: {field_names}")
    except Exception:
        logger.info("ğŸ§¬ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•¨")

    return collection

def validate_query_embedding_dim(collection: Collection, embedding: List[float]):
    """ì„ë² ë”© ì°¨ì› ê²€ì¦."""
    col_dim = _get_embedding_dim_from_schema(collection)
    if len(embedding) != col_dim:
        raise ValueError(f"ì„ë² ë”© ì°¨ì› ë¶ˆì¼ì¹˜: query={len(embedding)}, collection={col_dim}")

def choose_search_params(collection: Collection) -> Dict[str, Any]:
    """ì¸ë±ìŠ¤ ìœ í˜•ì— ë§ëŠ” ìµœì í™”ëœ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„ íƒ."""
    index_type = None
    try:
        if collection.indexes:
            index_type = getattr(collection.indexes[0], "index_type", None)
    except Exception:
        pass

    # Milvus LiteëŠ” FLAT, IVF_FLAT, AUTOINDEXë§Œ ì§€ì›
    if index_type and "IVF" in str(index_type).upper():
        return {"metric_type": "COSINE", "params": {"nprobe": 16}}
    # FLAT ë˜ëŠ” AUTOINDEX (ê¸°ë³¸ê°’)
    return {"metric_type": "COSINE", "params": {}}

def check_milvus_connection():
    """Milvus Lite ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        connections.connect("default", uri=MILVUS_URI)
        logger.info(f"âœ… Milvus Lite ì—°ê²° ì„±ê³µ: {MILVUS_URI}")
        return True
    except Exception as e:
        logger.error(f"âŒ Milvus Lite ì—°ê²° ì‹¤íŒ¨: {str(e)}")
        return False

def check_collection_exists():
    """ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        if utility.has_collection(MILVUS_COLLECTION_NAME):
            collection = Collection(MILVUS_COLLECTION_NAME)
            collection.load()
            
            # ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
            logger.info(f"âœ… ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION_NAME}' ì¡´ì¬")
            
            # ë°ì´í„° ê°œìˆ˜ í™•ì¸
            num_entities = collection.num_entities
            logger.info(f"ğŸ“Š ì»¬ë ‰ì…˜ ë‚´ ë°ì´í„° ê°œìˆ˜: {num_entities}ê°œ")
            
            return True, num_entities
        else:
            logger.warning(f"âš ï¸ ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION_NAME}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return False, 0
    except Exception as e:
        logger.error(f"âŒ ì»¬ë ‰ì…˜ í™•ì¸ ì‹¤íŒ¨: {str(e)}")
        return False, 0

def search_combined_vectors(query: str, top_k: int = 5) -> Dict[str, Any]:
    """í†µí•© ë²¡í„°ì—ì„œ ê²€ìƒ‰"""
    logger.info(f"ğŸ” í†µí•© ë²¡í„° ê²€ìƒ‰: {query}")
    
    try:
        collection = debug_and_prepare_collection()

        # ì¿¼ë¦¬ ì„ë² ë”© ë° ì°¨ì› ê²€ì¦
        query_embedding = get_azure_openai_embedding(query)
        validate_query_embedding_dim(collection, query_embedding)

        # ì¸ë±ìŠ¤ì— ë§ëŠ” ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„ íƒ
        search_params = choose_search_params(collection)

        t0 = time.time()
        results = collection.search(
            [query_embedding],
            "embedding",
            search_params,
            limit=top_k,
            output_fields=["document_path", "page_number", "content_type", "content", 
                          "text_content", "image_description", "image_path"]
        )
        logger.info(f"â±ï¸ ê²€ìƒ‰ ì‹œê°„: {time.time()-t0:.3f}s")
        
        # ê²°ê³¼ ì •ë¦¬
        search_results = []
        for hits in results:
            for hit in hits:
                search_results.append({
                    "score": float(hit.score),
                    "document_path": hit.entity.get("document_path"),
                    "page_number": hit.entity.get("page_number"),
                    "content_type": hit.entity.get("content_type"),
                    "content": hit.entity.get("content"),
                    "text_content": hit.entity.get("text_content"),
                    "image_description": hit.entity.get("image_description"),
                    "image_path": hit.entity.get("image_path")
                })
        
        logger.info(f"âœ… í†µí•© ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
        return {
            "search_type": "combined_vectors",
            "query": query,
            "results": search_results,
            "total_results": len(search_results)
        }
        
    except Exception as e:
        logger.error(f"âŒ í†µí•© ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise

def search_text_only(query: str, top_k: int = 5) -> Dict[str, Any]:
    """í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë§Œ ê²€ìƒ‰"""
    logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ì „ìš© ê²€ìƒ‰: {query}")
    
    try:
        collection = debug_and_prepare_collection()

        query_embedding = get_azure_openai_embedding(query)
        validate_query_embedding_dim(collection, query_embedding)

        search_params = choose_search_params(collection)

        t0 = time.time()
        results = collection.search(
            [query_embedding],
            "embedding",
            search_params,
            limit=top_k,
            output_fields=["document_path", "page_number", "content_type", "content", 
                          "text_content", "image_description", "image_path"]
        )
        logger.info(f"â±ï¸ ê²€ìƒ‰ ì‹œê°„: {time.time()-t0:.3f}s")
        
        # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²°ê³¼ë§Œ í•„í„°ë§
        search_results = []
        for hits in results:
            for hit in hits:
                text_content = hit.entity.get("text_content", "")
                if text_content.strip():  # í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    search_results.append({
                        "score": float(hit.score),
                        "document_path": hit.entity.get("document_path"),
                        "page_number": hit.entity.get("page_number"),
                        "content_type": "text_only",
                        "text_content": text_content,
                        "image_path": hit.entity.get("image_path")
                    })
        
        logger.info(f"âœ… í…ìŠ¤íŠ¸ ì „ìš© ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
        return {
            "search_type": "text_only",
            "query": query,
            "results": search_results,
            "total_results": len(search_results)
        }
        
    except Exception as e:
        logger.error(f"âŒ í…ìŠ¤íŠ¸ ì „ìš© ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise

def search_image_only(query: str, top_k: int = 5) -> Dict[str, Any]:
    """ì´ë¯¸ì§€ ì„¤ëª…ë§Œ ê²€ìƒ‰"""
    logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ì „ìš© ê²€ìƒ‰: {query}")
    
    try:
        collection = debug_and_prepare_collection()

        query_embedding = get_azure_openai_embedding(query)
        validate_query_embedding_dim(collection, query_embedding)

        search_params = choose_search_params(collection)

        t0 = time.time()
        results = collection.search(
            [query_embedding],
            "embedding",
            search_params,
            limit=top_k,
            output_fields=["document_path", "page_number", "content_type", "content", 
                          "text_content", "image_description", "image_path"]
        )
        logger.info(f"â±ï¸ ê²€ìƒ‰ ì‹œê°„: {time.time()-t0:.3f}s")
        
        # ì´ë¯¸ì§€ ì„¤ëª…ì´ ìˆëŠ” ê²°ê³¼ë§Œ í•„í„°ë§ (ì˜¤ë¥˜ ë©”ì‹œì§€ ì œì™¸)
        search_results = []
        for hits in results:
            for hit in hits:
                image_description = hit.entity.get("image_description", "")
                image_path = hit.entity.get("image_path", "")
                # ì´ë¯¸ì§€ ì„¤ëª…ì´ ìˆê³ , ì˜¤ë¥˜ ë©”ì‹œì§€ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
                if (image_description.strip() and image_path and 
                    not image_description.startswith("ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")):
                    search_results.append({
                        "score": float(hit.score),
                        "document_path": hit.entity.get("document_path"),
                        "page_number": hit.entity.get("page_number"),
                        "content_type": "image_only",
                        "image_description": image_description,
                        "image_path": image_path
                    })
        
        logger.info(f"âœ… ì´ë¯¸ì§€ ì „ìš© ê²€ìƒ‰ ì™„ë£Œ: {len(search_results)}ê°œ ê²°ê³¼")
        return {
            "search_type": "image_only",
            "query": query,
            "results": search_results,
            "total_results": len(search_results)
        }
        
    except Exception as e:
        logger.error(f"âŒ ì´ë¯¸ì§€ ì „ìš© ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        raise

def print_search_results(results):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{results['query']}'")
    print("=" * 80)
    
    # ê° ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
    for search_type, search_result in results["results"].items():
        if "error" in search_result:
            print(f"\nâŒ {search_type.upper()} ê²€ìƒ‰ ì˜¤ë¥˜: {search_result['error']}")
            continue
            
        print(f"\nğŸ“Š {search_type.upper()} ê²€ìƒ‰ ê²°ê³¼:")
        print("-" * 50)
        
        for i, result in enumerate(search_result["results"][:3], 1):
            print(f"{i}. í˜ì´ì§€ {result['page_number']} (ì ìˆ˜: {result['score']:.3f})")
            print(f"   ğŸ”§ íƒ€ì…: {result.get('content_type', 'unknown')}")
            
            # í…ìŠ¤íŠ¸ ë‚´ìš© (ìˆëŠ” ê²½ìš°)
            if result.get('text_content') and result['text_content'].strip():
                text_content = result['text_content'].strip()
                if len(text_content) > 150:
                    text_preview = text_content[:150] + "..."
                else:
                    text_preview = text_content
                print(f"   ğŸ“ í…ìŠ¤íŠ¸: {text_preview}")
            
            # ì´ë¯¸ì§€ ì„¤ëª… (ìˆëŠ” ê²½ìš°)
            if result.get('image_description') and result['image_description'].strip():
                img_desc = result['image_description'].strip()
                # ì˜¤ë¥˜ ë©”ì‹œì§€ ì œì™¸
                if not img_desc.startswith("ì£„ì†¡í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"):
                    if len(img_desc) > 150:
                        img_preview = img_desc[:150] + "..."
                    else:
                        img_preview = img_desc
                    print(f"   ğŸ–¼ï¸ ì´ë¯¸ì§€: {img_preview}")
            
            # ì´ë¯¸ì§€ ê²½ë¡œ (ìˆëŠ” ê²½ìš°)
            if result.get('image_path') and result['image_path'].strip():
                image_filename = result['image_path'].split('/')[-1]
                print(f"   ğŸ“ ì´ë¯¸ì§€: {image_filename}")
            
            # ì „ì²´ ë‚´ìš© (combined ë‚´ìš©)
            if result.get('content') and result['content'].strip():
                content = result['content'].strip()
                if len(content) > 100:
                    content_preview = content[:100] + "..."
                else:
                    content_preview = content
                print(f"   ğŸ“‹ ì „ì²´: {content_preview}")
            
            print()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Milvus ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ ì‹œì‘")
    print("=" * 80)
    
    # 1. Milvus ì—°ê²° í™•ì¸
    if not check_milvus_connection():
        print("âŒ Milvus ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return
    
    # 2. ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸
    collection_exists, num_entities = check_collection_exists()
    if not collection_exists:
        print("âŒ ê²€ìƒ‰í•  ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë¨¼ì € run_document_pipeline.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ êµ¬ì¶•í•´ì£¼ì„¸ìš”.")
        return
    
    if num_entities == 0:
        print("âš ï¸ ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë¨¼ì € run_document_pipeline.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ êµ¬ì¶•í•´ì£¼ì„¸ìš”.")
        return
    
    # 3. ê²€ìƒ‰ ì¿¼ë¦¬ ì…ë ¥
    if len(sys.argv) > 1:
        query = " ".join(sys.argv[1:])
    else:
        query = input("\nğŸ” ê²€ìƒ‰í•  ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”: ")
    
    if not query.strip():
        print("âŒ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        # 4. ê²€ìƒ‰ ì‹¤í–‰
        print(f"\nğŸ”„ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
        
        search_results = {
            "query": query,
            "results": {}
        }
        
        # í†µí•© ê²€ìƒ‰
        try:
            combined_results = search_combined_vectors(query, 5)
            search_results["results"]["combined"] = combined_results
        except Exception as e:
            search_results["results"]["combined"] = {"error": str(e)}
        
        # í…ìŠ¤íŠ¸ ì „ìš© ê²€ìƒ‰
        try:
            text_results = search_text_only(query, 5)
            search_results["results"]["text_only"] = text_results
        except Exception as e:
            search_results["results"]["text_only"] = {"error": str(e)}
        
        # ì´ë¯¸ì§€ ì „ìš© ê²€ìƒ‰
        try:
            image_results = search_image_only(query, 5)
            search_results["results"]["image_only"] = image_results
        except Exception as e:
            search_results["results"]["image_only"] = {"error": str(e)}
        
        # ê²°ê³¼ ì¶œë ¥
        print_search_results(search_results)
        print("\nâœ… ê²€ìƒ‰ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ ê²€ìƒ‰ ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    main()